{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/themeeemul/fungi-classification-using-resnet50-with-pytorch?scriptVersionId=143884441\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom PIL import Image\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom collections import defaultdict\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import KFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-22T13:34:20.973984Z","iopub.execute_input":"2023-09-22T13:34:20.974325Z","iopub.status.idle":"2023-09-22T13:34:21.771888Z","shell.execute_reply.started":"2023-09-22T13:34:20.974297Z","shell.execute_reply":"2023-09-22T13:34:21.770834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load the extension and start TensorBoard\n\n# %load_ext tensorboard\n# %tensorboard --logdir logs","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:34:22.335986Z","iopub.execute_input":"2023-09-22T13:34:22.336436Z","iopub.status.idle":"2023-09-22T13:34:22.341025Z","shell.execute_reply.started":"2023-09-22T13:34:22.336406Z","shell.execute_reply":"2023-09-22T13:34:22.340021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms, models\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader,Dataset,ConcatDataset, SubsetRandomSampler\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:34:22.991638Z","iopub.execute_input":"2023-09-22T13:34:22.99204Z","iopub.status.idle":"2023-09-22T13:34:26.945345Z","shell.execute_reply.started":"2023-09-22T13:34:22.99201Z","shell.execute_reply":"2023-09-22T13:34:26.94436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Set a random seed\nseed = 42\ntorch.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False  # Disable CuDNN benchmarking for reproducibility\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:58:00.612901Z","iopub.execute_input":"2023-09-22T13:58:00.613576Z","iopub.status.idle":"2023-09-22T13:58:00.622697Z","shell.execute_reply.started":"2023-09-22T13:58:00.613543Z","shell.execute_reply":"2023-09-22T13:58:00.62171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = \"/kaggle/input/microscopic-fungi-images/train\"\nvalid_path = \"/kaggle/input/microscopic-fungi-images/valid\"\ntest_path = \"/kaggle/input/microscopic-fungi-images/test\"","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:34:26.947244Z","iopub.execute_input":"2023-09-22T13:34:26.947791Z","iopub.status.idle":"2023-09-22T13:34:26.952617Z","shell.execute_reply.started":"2023-09-22T13:34:26.947756Z","shell.execute_reply":"2023-09-22T13:34:26.951699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Distribution of each class in dataset","metadata":{}},{"cell_type":"code","source":"train_datasets = ImageFolder(root = train_path)\nvalid_datasets = ImageFolder(root = valid_path)\ntest_datasets = ImageFolder(root= test_path)\nlabel_dict = defaultdict(int)\n\nfor _,label in train_datasets:\n    label_dict[label] +=1\nclass_list = []\nclass_count = []\nfor class_idx, count in label_dict.items():\n    class_list.append(class_idx)\n    class_count.append(class_count)\n    print(\"Class idx: \",class_idx, \"|| count: \",count)\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:34:26.953992Z","iopub.execute_input":"2023-09-22T13:34:26.954899Z","iopub.status.idle":"2023-09-22T13:34:48.9835Z","shell.execute_reply.started":"2023-09-22T13:34:26.954813Z","shell.execute_reply":"2023-09-22T13:34:48.982594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Finding mean and std for normalization later on\n# or you can use mean and std that provided from imagenet mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\nmean = 0.0\nstd = 0.0\nnum_samples = 0\nimage_sizes = defaultdict(int)\nfor data, _ in train_datasets:\n    height,width = data.size\n    image_sizes[(height,width)]+=1\n    image_array = np.array(data)\n      \n    # Update mean and std\n    mean += np.mean(image_array,axis=(0,1))\n    std += np.std(image_array,axis = (0,1))\n    num_samples += 1\n\nmean /= num_samples\nstd /= num_samples","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:34:48.98768Z","iopub.execute_input":"2023-09-22T13:34:48.988665Z","iopub.status.idle":"2023-09-22T13:35:25.425513Z","shell.execute_reply.started":"2023-09-22T13:34:48.98863Z","shell.execute_reply":"2023-09-22T13:35:25.424463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mean,std)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:35:25.427099Z","iopub.execute_input":"2023-09-22T13:35:25.427496Z","iopub.status.idle":"2023-09-22T13:35:25.433936Z","shell.execute_reply.started":"2023-09-22T13:35:25.427454Z","shell.execute_reply":"2023-09-22T13:35:25.432836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for size, count in image_sizes.items():\n    print(f\"Image size {size}: {count} images\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:35:25.435594Z","iopub.execute_input":"2023-09-22T13:35:25.436293Z","iopub.status.idle":"2023-09-22T13:35:25.447082Z","shell.execute_reply.started":"2023-09-22T13:35:25.436246Z","shell.execute_reply":"2023-09-22T13:35:25.445805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing Data","metadata":{}},{"cell_type":"code","source":"# Gaussian Blur\nclass Gaussian_Blur(object):\n    def __init__(self,radius = 2):\n        if radius % 2 == 0:\n            radius += 1  # Make sure radius is odd\n        self.radius = radius\n    def __call__(self,img):\n        return transforms.GaussianBlur(self.radius)(img)\nclass HistogramEqualization(object):\n    def __call__(self,img):\n        return transforms.functional.equalize(img)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:35:25.448594Z","iopub.execute_input":"2023-09-22T13:35:25.449272Z","iopub.status.idle":"2023-09-22T13:35:25.460043Z","shell.execute_reply.started":"2023-09-22T13:35:25.449236Z","shell.execute_reply":"2023-09-22T13:35:25.459011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transforms ={\n    \"train\":\n        transforms.Compose([\n            transforms.Resize([224,224]),\n            HistogramEqualization(),\n            Gaussian_Blur(radius = 2),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    ,\n    \"test-valid\":\n        transforms.Compose([\n            transforms.Resize([224,224]),\n            HistogramEqualization(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    \n} ","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:36:12.298213Z","iopub.execute_input":"2023-09-22T13:36:12.298676Z","iopub.status.idle":"2023-09-22T13:36:12.310963Z","shell.execute_reply.started":"2023-09-22T13:36:12.298638Z","shell.execute_reply":"2023-09-22T13:36:12.309822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Fungi(Dataset):\n    def __init__(self,dataset,transforms = None):\n        self.dataset = dataset\n        self.transforms = transforms\n    def __len__(self):\n        return len(self.dataset)\n    def __getitem__(self,idx):\n        image,label = self.dataset[idx]\n        \n        if self.transforms:\n            image = self.transforms(image) \n        sample = {\"image\":image,\"label\":label}   \n        return sample","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:36:12.86839Z","iopub.execute_input":"2023-09-22T13:36:12.868735Z","iopub.status.idle":"2023-09-22T13:36:12.875332Z","shell.execute_reply.started":"2023-09-22T13:36:12.868707Z","shell.execute_reply":"2023-09-22T13:36:12.874107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = Fungi(train_datasets,data_transforms['train'])\nvalid_dataset = Fungi(valid_datasets,data_transforms['test-valid'])\ntest_dataset = Fungi(valid_datasets,data_transforms['test-valid'])","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:36:13.168265Z","iopub.execute_input":"2023-09-22T13:36:13.168615Z","iopub.status.idle":"2023-09-22T13:36:13.173818Z","shell.execute_reply.started":"2023-09-22T13:36:13.168588Z","shell.execute_reply":"2023-09-22T13:36:13.172619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def show_image(image_tensor):\n#     # Convert the image tensor to a NumPy array\n#     image_array = image_tensor.numpy()\n\n#     # If the image has 3 channels (e.g., RGB), transpose it to (H, W, C) for display\n#     if image_array.shape[0] == 3:\n#         image_array = image_array.transpose(1, 2, 0)\n\n#     # Display the image using Matplotlib\n#     plt.imshow(image_array)\n#     plt.axis('off')\n#     plt.show()\n\n# # Load a batch of data (change 'next(iter(data_loader))' to access different batches)\n# batch = next(iter(train_loader))\n\n# # Extract an image from the batch (change '0' to access different images within the batch)\n# image = batch['image'][0]\n\n# # Display the image\n# show_image(image)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:36:13.48947Z","iopub.execute_input":"2023-09-22T13:36:13.489823Z","iopub.status.idle":"2023-09-22T13:36:13.49469Z","shell.execute_reply.started":"2023-09-22T13:36:13.489793Z","shell.execute_reply":"2023-09-22T13:36:13.493469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define model","metadata":{}},{"cell_type":"code","source":"def initialize_network():\n    model = models.resnet50(weights=\"IMAGENET1K_V2\").to(device)\n#     # Freezing\n#     for param in model.parameters():\n#         param.requires_grad = False   \n\n    num_ftrs = model.fc.in_features\n\n    model.fc = nn.Sequential(\n                   nn.BatchNorm1d(num_ftrs),\n                   nn.Dropout(0.5),\n                   nn.Linear(2048, 1024),\n                   nn.ReLU(inplace=True),\n                   nn.Linear(1024, 512),\n                   nn.ReLU(inplace=True),\n                   nn.BatchNorm1d(512),\n                   nn.Dropout(0.5),\n                   nn.Linear(512, 5)).to(device)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-22T14:30:30.620571Z","iopub.execute_input":"2023-09-22T14:30:30.620941Z","iopub.status.idle":"2023-09-22T14:30:30.630551Z","shell.execute_reply.started":"2023-09-22T14:30:30.620911Z","shell.execute_reply":"2023-09-22T14:30:30.629525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feedNN(model,loader,type):\n    total_loss = 0\n    num_samples = 0\n    prediction_list = []\n    label_list = []\n    for i,data in enumerate(loader):\n        images = data['image'].to(device)\n        labels = data['label'].to(device)\n        \n        \n        \n        #Feed it to model\n        outputs = model(images)\n        #Loss function\n        loss = criterion(outputs,labels)\n        if(type == \"train\"):\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        \n        total_loss +=loss.item()\n        # number of samples\n        num_samples += images.size()[0]\n        #Prediction\n        prediction_list.append(torch.argmax(outputs,dim = 1).cpu().detach().numpy())\n        label_list.append(labels.cpu().detach().numpy())\n    \n    average_loss = total_loss/num_samples\n    prediction_list = np.concatenate(prediction_list).ravel()\n    label_list = np.concatenate(label_list).ravel()\n    return average_loss , prediction_list , label_list\n        \n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-22T14:30:31.361009Z","iopub.execute_input":"2023-09-22T14:30:31.361375Z","iopub.status.idle":"2023-09-22T14:30:31.370805Z","shell.execute_reply.started":"2023-09-22T14:30:31.361346Z","shell.execute_reply":"2023-09-22T14:30:31.369691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotting(train_acc,valid_acc,train_loss,valid_loss):\n    plt.subplot(1,2,1)\n    plt.title(\"Accuracy\")\n    epochs = range(1,11)\n    plt.plot(epochs,train_acc,'g', label='Training Accuracy')\n    plt.plot(epochs,valid_acc,'r', label='Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()\n    \n    plt.subplot(1,2,2)\n    plt.title(\"Loss\")\n    epochs = range(1,11)\n    plt.plot(epochs,train_loss,'g', label='Training Loss')\n    plt.plot(epochs,valid_loss,'r', label='Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T14:30:31.556703Z","iopub.execute_input":"2023-09-22T14:30:31.557404Z","iopub.status.idle":"2023-09-22T14:30:31.564524Z","shell.execute_reply.started":"2023-09-22T14:30:31.557372Z","shell.execute_reply":"2023-09-22T14:30:31.563554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyperparameters = {\n    \"batch_size\":2\n}","metadata":{"execution":{"iopub.status.busy":"2023-09-22T14:30:31.666602Z","iopub.execute_input":"2023-09-22T14:30:31.667163Z","iopub.status.idle":"2023-09-22T14:30:31.671865Z","shell.execute_reply.started":"2023-09-22T14:30:31.667128Z","shell.execute_reply":"2023-09-22T14:30:31.670757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concat_dataset = ConcatDataset([train_dataset,valid_dataset])\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_loader = DataLoader(concat_dataset,batch_size = 16,shuffle=True)\nvalid_loader = DataLoader(concat_dataset,batch_size = 16, shuffle = False)\ntest_loader = DataLoader(concat_dataset,batch_size = 16, shuffle = False)\n\n# Initialize of the network \nmodel = initialize_network()\n# Initialize of the Optimizer and Loss Function\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(),lr=0.001)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T14:30:31.831722Z","iopub.execute_input":"2023-09-22T14:30:31.832052Z","iopub.status.idle":"2023-09-22T14:30:32.331565Z","shell.execute_reply.started":"2023-09-22T14:30:31.832026Z","shell.execute_reply":"2023-09-22T14:30:32.330545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torch.utils.tensorboard import SummaryWriter\n# log_dir = \"./logs\"  # Specify a directory for TensorBoard logs\n# writer = SummaryWriter(log_dir)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T14:30:32.333547Z","iopub.execute_input":"2023-09-22T14:30:32.33389Z","iopub.status.idle":"2023-09-22T14:30:32.338892Z","shell.execute_reply.started":"2023-09-22T14:30:32.333856Z","shell.execute_reply":"2023-09-22T14:30:32.337936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch = 10\n\ntrain_list = {\"acc\":[],\"loss\":[]}\nvalid_list = {\"acc\":[],\"loss\":[]}\nfor i in range(0,epoch):\n    print(\"==================\")\n    print(\"Epoch : \",i+1)\n\n    #Train our model\n    model.train()\n    train_loss, train_preds, train_labels = feedNN(model,train_loader,\"train\")\n    model.eval()\n    with torch.no_grad():\n        valid_loss, valid_preds, valid_labels = feedNN(model,valid_loader,\"valid\")\n    #Metrics\n    print(\"Train_Accuracy: \",accuracy_score(train_labels,train_preds), \"| Valid_Accuracy: \",accuracy_score(valid_labels,valid_preds))\n    print(\"Train_loss: \",train_loss,\"| Valid_loss : \",valid_loss)\n#     #store acc and loss for plotting later on\n    \n#     writer.add_scalar(\"Training Loss\", train_loss, global_step=i)\n#     writer.add_scalar(\"Training Accuracy\", train_preds, global_step=i)\n    \n    train_list['acc'].append(accuracy_score(train_labels,train_preds))\n    valid_list['acc'].append(accuracy_score(valid_labels,valid_preds))\n    train_list['loss'].append(train_loss)\n    valid_list['loss'].append(valid_loss)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T14:30:32.340119Z","iopub.execute_input":"2023-09-22T14:30:32.340914Z","iopub.status.idle":"2023-09-22T14:57:22.650459Z","shell.execute_reply.started":"2023-09-22T14:30:32.340879Z","shell.execute_reply":"2023-09-22T14:57:22.64944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotting(train_list['acc'],valid_list['acc'],train_list['loss'],valid_list['loss'])\ntorch.save(model.state_dict(),\"resnet50_1.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T14:58:15.596626Z","iopub.execute_input":"2023-09-22T14:58:15.597016Z","iopub.status.idle":"2023-09-22T14:58:16.363103Z","shell.execute_reply.started":"2023-09-22T14:58:15.596978Z","shell.execute_reply":"2023-09-22T14:58:16.362019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    test_loss, test_preds, test_labels = feedNN(model,test_loader,\"test\")\n# classification_report,confusion_matrix\nprint(\"Testing result\")\nprint(classification_report(test_labels,test_preds))\nprint(\"=======================================\")\nprint(confusion_matrix(test_labels,test_preds))","metadata":{"execution":{"iopub.status.busy":"2023-09-22T14:58:18.906886Z","iopub.execute_input":"2023-09-22T14:58:18.907286Z","iopub.status.idle":"2023-09-22T14:59:15.436687Z","shell.execute_reply.started":"2023-09-22T14:58:18.907245Z","shell.execute_reply":"2023-09-22T14:59:15.435557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLink\n\n# # Create a download link for the model file\n# FileLink('resnet50_1.pt')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T15:01:24.065572Z","iopub.execute_input":"2023-09-22T15:01:24.066178Z","iopub.status.idle":"2023-09-22T15:01:24.076864Z","shell.execute_reply.started":"2023-09-22T15:01:24.066133Z","shell.execute_reply":"2023-09-22T15:01:24.075657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.eval()  # Set the model to evaluation mode\n\n# predicted_list = []\n# label_list = []\n# with torch.no_grad():\n#     for inputs in test_loader:  # Iterate through the test dataset\n#         images = inputs['image']\n#         labels = inputs['label']\n#         outputs = model(images)  # Forward pass\n#         predicted = torch.argmax(outputs, 1)  # Get predicted labels\n#         predicted_list.append(predicted.cpu().detach().numpy())\n#         label_list.append(labels.cpu().detach().numpy())\n        \n# predicted_list = np.concatenate(predicted_list).ravel()\n# label_list  = np.concatenate(label_list).ravel()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:09:50.854997Z","iopub.status.idle":"2023-09-22T13:09:50.855811Z","shell.execute_reply.started":"2023-09-22T13:09:50.855544Z","shell.execute_reply":"2023-09-22T13:09:50.855581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # classification_report,confusion_matrix\n# print(\"Testing result\")\n# print(classification_report(label_list,predicted_list))\n# print(\"=======================================\")\n# print(confusion_matrix(label_list,predicted_list))","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:09:50.857164Z","iopub.status.idle":"2023-09-22T13:09:50.857955Z","shell.execute_reply.started":"2023-09-22T13:09:50.857686Z","shell.execute_reply":"2023-09-22T13:09:50.857709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# k = 2\n# # Define device\n# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# # Define the K-fold Cross Validator\n# kfold = KFold(n_splits=k, shuffle=True)\n    \n# # Start print\n# print('--------------------------------')\n\n# # K-fold Cross Validation model evaluation\n# for fold, (train_ids, valid_ids) in enumerate(kfold.split(concat_dataset)):\n#     print(\"Fold: \",fold+1)\n#     train_subsampler = SubsetRandomSampler(train_ids)\n#     valid_subsampler = SubsetRandomSampler(valid_ids)\n    \n#     #Data Loader\n#     train_loader = DataLoader(concat_dataset,batch_size = 16,sampler = train_subsampler)\n#     valid_loader = DataLoader(concat_dataset,batch_size = 16,sampler = valid_subsampler)\n    \n#     # Initialize of the network \n#     model = initialize_network()\n#     # Initialize of the Optimizer and Loss Function\n#     criterion = nn.CrossEntropyLoss()\n#     optimizer = optim.Adam(model.fc.parameters(),lr=0.001)\n#     # Train\n#     epoch = 10\n    \n#     train_list = {\"acc\":[],\"loss\":[]}\n#     valid_list = {\"acc\":[],\"loss\":[]}\n#     for i in range(0,epoch):\n#         print(\"==================\")\n#         print(\"Epoch : \",i+1)\n        \n#         #Train our model\n#         model.train()\n#         train_loss, train_preds, train_labels = feedNN(model,train_loader)\n#         model.eval()\n#         valid_loss, valid_preds, valid_labels = feedNN(model,valid_loader)\n#         #Metrics\n#         print(\"Train_Accuracy: \",accuracy_score(train_labels,train_preds), \"| Valid_Accuracy: \",accuracy_score(valid_labels,valid_preds))\n#         print(\"Train_loss: \",train_loss,\"| Valid_loss : \",valid_loss)\n#         #store acc and loss for plotting later on\n#         train_list['acc'].append(accuracy_score(train_labels,train_preds))\n#         valid_list['acc'].append(accuracy_score(valid_labels,valid_preds))\n#         train_list['loss'].append(train_loss)\n#         valid_list['loss'].append(valid_loss)\n        \n#     print(\"Plot Fold: \",fold)\n#     plotting(train_list['acc'],valid_list['acc'],train_list['loss'],valid_list['loss'])\n# torch.save(model.state_dict(),\"resnet50_1.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T13:09:50.859327Z","iopub.status.idle":"2023-09-22T13:09:50.860063Z","shell.execute_reply.started":"2023-09-22T13:09:50.859828Z","shell.execute_reply":"2023-09-22T13:09:50.859851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}